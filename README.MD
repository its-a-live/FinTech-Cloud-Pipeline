# Data Pipeline для FinTech

**ETL-пайплайн для анализа транзакционной активности пользователей финтех-стартапа**

---

## Описание проекта

Проект реализует систему обработки данных на основе микросервисов для финтех-стартапа. Архитектура основана на принципах ETL (Extract, Transform, Load) и предназначена для сбора, обработки и аналитики пользовательских транзакций. Каждый этап пайплайна реализован в виде отдельного микросервиса, взаимодействующего через Kafka и работающего с postgres.

---

## Стек технологий

- **Yandex Cloud**: Managed Kafka, Container Registry, Kubernetes
- **Базы данных**: Postgres (DWH)
- **Обработка данных**: Python, Pydantic, Spark

---

## Структура сервисов

### 1. Сервис STG (`stg_loader`)

**Назначение:** Загрузка сырых данных в слой STG.

**Функционал:**
- Чтение сообщений из Kafka
- Сохранение в таблицу 
- Обогащение данных (пользователи, рестораны) через Redis
- Отправка преобразованных данных в новый топик Kafka

---

### 2. Сервис DDS (`dds_loader`)

**Назначение:** Формирование детализированного слоя DDS.

**Функционал:**
- Загрузка данных в хаб-таблицы (`h_user`, `h_product` и др.)
- Заполнение связующих таблиц (`l_order_product`, `l_product_restaurant`)
- Ведение сателлитов (`s_user_names`, `s_product_names`)

---

### 3. Сервис CDM (`cdm_loader`)

**Назначение:** Построение аналитических витрин.

**Функционал:**
- Агрегация данных (популярность продуктов/категорий)
- Заполнение таблиц `cdm.user_product_counters` и `cdm.user_category_counters`
